{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Step 1: Install Dependencies\n",
        "!pip install deepface\n",
        "!pip install tqdm\n",
        "!pip install scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MQlNDEkn7r1",
        "outputId": "c8b480b0-445e-48b9-a086-7aeef43adbe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepface\n",
            "  Downloading deepface-0.0.93-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.2.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (5.2.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.67.1)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (11.1.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.11.0.86)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.18.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.8.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.1.0)\n",
            "Collecting flask-cors>=4.0.1 (from deepface)\n",
            "  Downloading flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
            "Collecting mtcnn>=0.1.0 (from deepface)\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting retina-face>=0.0.1 (from deepface)\n",
            "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fire>=0.4.0 (from deepface)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gunicorn>=20.1.0 (from deepface)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.4.0->deepface) (2.5.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (1.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (3.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gunicorn>=20.1.0->deepface) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.4.1)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface) (1.4.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn>=0.1.0->deepface)\n",
            "  Downloading lz4-4.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2025.1.31)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=1.1.2->deepface) (3.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
            "Downloading deepface-0.0.93-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.6/108.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
            "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
            "Downloading lz4-4.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=41776d2258394d152f8a1a3ac8fa43c0d26340c03fcc3f96f40134605398acf1\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: lz4, gunicorn, fire, mtcnn, flask-cors, retina-face, deepface\n",
            "Successfully installed deepface-0.0.93 fire-0.7.0 flask-cors-5.0.1 gunicorn-23.0.0 lz4-4.4.3 mtcnn-1.0.0 retina-face-0.0.17\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "!unzip -q dataset.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "iRpof3bEoJ4T",
        "outputId": "bd1c1805-24d2-4984-c0d7-911330db6d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1c0bb178-eaee-4a3e-8601-82b0a0c822ce\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1c0bb178-eaee-4a3e-8601-82b0a0c822ce\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset.zip to dataset.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 3: Prepare the Data and Extract Features\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from deepface import DeepFace\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define dataset path and labels mapping\n",
        "dataset_path = \"dataset\"  # make sure your zip unzips to a folder named 'dataset'\n",
        "label_map = {\"man\": 0, \"woman\": 1}\n",
        "\n",
        "# Prepare lists for embeddings and labels\n",
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "# Iterate over the subfolders (\"man\" and \"woman\")\n",
        "for gender in label_map.keys():\n",
        "    folder = os.path.join(dataset_path, gender)\n",
        "    if not os.path.isdir(folder):\n",
        "        print(f\"Folder {folder} not found.\")\n",
        "        continue\n",
        "    for file in tqdm(os.listdir(folder), desc=f\"Processing {gender} images\"):\n",
        "        file_path = os.path.join(folder, file)\n",
        "        # Read the image with OpenCV\n",
        "        img = cv2.imread(file_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        # You can optionally resize or preprocess here if needed\n",
        "\n",
        "        try:\n",
        "            # Extract the face embedding using DeepFace (default model is 'VGG-Face')\n",
        "            # enforce_detection=False allows processing even if a face is not detected.\n",
        "            representation = DeepFace.represent(img_path = file_path, model_name = 'VGG-Face', enforce_detection=False)\n",
        "            embeddings.append(representation[0][\"embedding\"])\n",
        "            labels.append(label_map[gender])\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X = np.array(embeddings)\n",
        "y = np.array(labels)\n",
        "\n",
        "print(\"Embeddings shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOBNXPjJLgT1",
        "outputId": "2fecf969-1021-4b9f-c4f8-2532aa9f3038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-03-28 14:55:28 - Directory /root/.deepface has been created\n",
            "25-03-28 14:55:28 - Directory /root/.deepface/weights has been created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing man images:   0%|          | 0/1173 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-03-28 14:55:30 - vgg_face_weights.h5 will be downloaded...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/vgg_face_weights.h5\n",
            "To: /root/.deepface/weights/vgg_face_weights.h5\n",
            "\n",
            "  0%|          | 0.00/580M [00:00<?, ?B/s]\u001b[A\n",
            "  4%|▎         | 21.0M/580M [00:00<00:02, 208MB/s]\u001b[A\n",
            " 10%|▉         | 56.1M/580M [00:00<00:01, 292MB/s]\u001b[A\n",
            " 16%|█▌        | 92.3M/580M [00:00<00:01, 322MB/s]\u001b[A\n",
            " 22%|██▏       | 128M/580M [00:00<00:01, 336MB/s] \u001b[A\n",
            " 28%|██▊       | 163M/580M [00:00<00:01, 327MB/s]\u001b[A\n",
            " 34%|███▎      | 196M/580M [00:00<00:01, 320MB/s]\u001b[A\n",
            " 39%|███▉      | 228M/580M [00:00<00:01, 304MB/s]\u001b[A\n",
            " 45%|████▍     | 260M/580M [00:00<00:01, 307MB/s]\u001b[A\n",
            " 50%|█████     | 290M/580M [00:00<00:00, 296MB/s]\u001b[A\n",
            " 55%|█████▌    | 320M/580M [00:01<00:00, 270MB/s]\u001b[A\n",
            " 60%|██████    | 348M/580M [00:01<00:00, 268MB/s]\u001b[A\n",
            " 65%|██████▍   | 375M/580M [00:01<00:00, 261MB/s]\u001b[A\n",
            " 69%|██████▉   | 402M/580M [00:01<00:00, 255MB/s]\u001b[A\n",
            " 74%|███████▍  | 431M/580M [00:01<00:00, 264MB/s]\u001b[A\n",
            " 79%|███████▉  | 459M/580M [00:01<00:00, 265MB/s]\u001b[A\n",
            " 84%|████████▍ | 486M/580M [00:01<00:00, 182MB/s]\u001b[A\n",
            " 88%|████████▊ | 513M/580M [00:01<00:00, 200MB/s]\u001b[A\n",
            " 93%|█████████▎| 542M/580M [00:02<00:00, 220MB/s]\u001b[A\n",
            "100%|██████████| 580M/580M [00:02<00:00, 259MB/s]\n",
            "Processing man images: 100%|██████████| 1173/1173 [03:52<00:00,  5.04it/s]\n",
            "Processing woman images: 100%|██████████| 1134/1134 [03:01<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: (2307, 4096)\n",
            "Labels shape: (2307,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 4: Train a Gender Classifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an SVM classifier\n",
        "clf = SVC(kernel='linear', probability=True)\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the classifier\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLDRjlHMNU9r",
        "outputId": "7c6d141d-8969-4fae-84a1-5652f13d35c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.987012987012987\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99       232\n",
            "           1       0.98      0.99      0.99       230\n",
            "\n",
            "    accuracy                           0.99       462\n",
            "   macro avg       0.99      0.99      0.99       462\n",
            "weighted avg       0.99      0.99      0.99       462\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 5: Save the Classifier (Optional)\n",
        "import joblib\n",
        "joblib.dump(clf, \"gender_classifier.pkl\")\n",
        "print(\"Model saved as gender_classifier.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "eXBBH5e9NbU2",
        "outputId": "ab2243d6-328c-4e4b-ed73-db73d7a6e897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'clf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1595253ff1b9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title Step 5: Save the Classifier (Optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gender_classifier.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model saved as gender_classifier.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 6: Test an Uploaded Image for Gender Classification\n",
        "from google.colab import files\n",
        "import cv2\n",
        "import numpy as np\n",
        "from deepface import DeepFace\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Upload an image\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Process each uploaded file\n",
        "for filename in uploaded.keys():\n",
        "    # Read the image using OpenCV\n",
        "    img = cv2.imread(filename)\n",
        "    if img is None:\n",
        "        print(\"Error reading the image file.\")\n",
        "        continue\n",
        "\n",
        "    # Display the image (convert from BGR to RGB for proper colors)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.title(\"Uploaded Image\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    # Extract face embedding using DeepFace\n",
        "    try:\n",
        "        # enforce_detection=False allows processing even if no face is detected\n",
        "        representation = DeepFace.represent(img_path=filename, model_name='VGG-Face', enforce_detection=False)\n",
        "        embedding = np.array(representation[0][\"embedding\"]).reshape(1, -1)\n",
        "    except Exception as e:\n",
        "        print(\"Error extracting embedding:\", e)\n",
        "        continue\n",
        "\n",
        "    # Load the saved classifier\n",
        "    clf = joblib.load(\"gender_classifier.pkl\")\n",
        "\n",
        "    # Predict the gender\n",
        "    prediction = clf.predict(embedding)\n",
        "    gender = \"man\" if prediction[0] == 0 else \"woman\"\n",
        "    print(\"Predicted Gender:\", gender)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "oFNb5_p4N4qb",
        "outputId": "db4809ee-c297-4815-ad1e-84883940d0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ae71528d-ddc0-4b0c-9ee6-9587f35156c6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ae71528d-ddc0-4b0c-9ee6-9587f35156c6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 7: Fairness Analysis for Treatment Equality\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Assuming X_test, y_test, and y_pred are available from your previous test evaluation\n",
        "# If not, ensure to run the test split and predictions cell first.\n",
        "\n",
        "# Convert y_test and y_pred to numpy arrays if needed\n",
        "y_test = np.array(y_test)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# Define the mapping for readability\n",
        "gender_map = {0: \"man\", 1: \"woman\"}\n",
        "\n",
        "def compute_group_metrics(y_true, y_pred, group_label):\n",
        "    # For the group, define:\n",
        "    # True Positive (TP): predicted as the group and truth is the group.\n",
        "    # False Positive (FP): predicted as the group but truth is not the group.\n",
        "    # False Negative (FN): truth is the group but predicted as the other.\n",
        "    # True Negative (TN): truth is not the group and predicted as not the group.\n",
        "    tp = np.sum((y_true == group_label) & (y_pred == group_label))\n",
        "    fp = np.sum((y_true != group_label) & (y_pred == group_label))\n",
        "    fn = np.sum((y_true == group_label) & (y_pred != group_label))\n",
        "    tn = np.sum((y_true != group_label) & (y_pred != group_label))\n",
        "\n",
        "    # Calculate error rates. Avoid division by zero.\n",
        "    fpr = fp / (fp + tn) if (fp + tn) != 0 else None\n",
        "    fnr = fn / (tp + fn) if (tp + fn) != 0 else None\n",
        "    # Treatment equality metric: ratio of false positives to false negatives.\n",
        "    te_ratio = fp / fn if fn != 0 else None\n",
        "\n",
        "    return {\n",
        "        \"TP\": tp, \"FP\": fp, \"FN\": fn, \"TN\": tn,\n",
        "        \"FPR\": fpr, \"FNR\": fnr, \"Treatment Equality (FP/FN)\": te_ratio\n",
        "    }\n",
        "\n",
        "# Compute metrics for each group\n",
        "results = {}\n",
        "for group in [0, 1]:\n",
        "    results[gender_map[group]] = compute_group_metrics(y_test, y_pred, group)\n",
        "\n",
        "# Display the results\n",
        "for gender, metrics in results.items():\n",
        "    print(f\"Metrics for {gender}:\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        print(f\"  {metric_name}: {value}\")\n",
        "    print()\n",
        "\n",
        "# Compare treatment equality ratios between groups\n",
        "te_ratio_man = results[\"man\"][\"Treatment Equality (FP/FN)\"]\n",
        "te_ratio_woman = results[\"woman\"][\"Treatment Equality (FP/FN)\"]\n",
        "\n",
        "print(\"Treatment Equality Ratio Comparison:\")\n",
        "if te_ratio_man is not None and te_ratio_woman is not None:\n",
        "    print(f\"  Man: {te_ratio_man:.2f} | Woman: {te_ratio_woman:.2f}\")\n",
        "    diff = abs(te_ratio_man - te_ratio_woman)\n",
        "    print(f\"  Difference in Treatment Equality Ratio: {diff:.2f}\")\n",
        "else:\n",
        "    print(\"  Unable to compute treatment equality ratio for one or both groups due to zero false negatives.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9D2bzTMOShL",
        "outputId": "c15752a4-598c-4a10-8e54-9fffae879405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for man:\n",
            "  TP: 228\n",
            "  FP: 2\n",
            "  FN: 4\n",
            "  TN: 228\n",
            "  FPR: 0.008695652173913044\n",
            "  FNR: 0.017241379310344827\n",
            "  Treatment Equality (FP/FN): 0.5\n",
            "\n",
            "Metrics for woman:\n",
            "  TP: 228\n",
            "  FP: 4\n",
            "  FN: 2\n",
            "  TN: 228\n",
            "  FPR: 0.017241379310344827\n",
            "  FNR: 0.008695652173913044\n",
            "  Treatment Equality (FP/FN): 2.0\n",
            "\n",
            "Treatment Equality Ratio Comparison:\n",
            "  Man: 0.50 | Woman: 2.00\n",
            "  Difference in Treatment Equality Ratio: 1.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming y_test and y_pred are available as numpy arrays.\n",
        "# Define the mapping for readability (as before)\n",
        "gender_map = {0: \"man\", 1: \"woman\"}\n",
        "\n",
        "def compute_tpr(y_true, y_pred, group_label):\n",
        "    # True Positive (TP): correctly predicted as the group.\n",
        "    tp = np.sum((y_true == group_label) & (y_pred == group_label))\n",
        "    # False Negative (FN): true group but predicted as other.\n",
        "    fn = np.sum((y_true == group_label) & (y_pred != group_label))\n",
        "\n",
        "    tpr = tp / (tp + fn) if (tp + fn) != 0 else None\n",
        "    return tpr\n",
        "\n",
        "# Compute TPR (Equality of Opportunity) for each group\n",
        "tpr_results = {}\n",
        "for group in [0, 1]:\n",
        "    tpr_results[gender_map[group]] = compute_tpr(y_test, y_pred, group)\n",
        "\n",
        "# Display the TPR results for each group\n",
        "for gender, tpr in tpr_results.items():\n",
        "    print(f\"TPR (Equality of Opportunity) for {gender}: {tpr:.2f}\" if tpr is not None else f\"TPR for {gender}: Not computable\")\n",
        "\n",
        "# Compare the TPR differences between groups\n",
        "if tpr_results[\"man\"] is not None and tpr_results[\"woman\"] is not None:\n",
        "    diff_tpr = abs(tpr_results[\"man\"] - tpr_results[\"woman\"])\n",
        "    print(\"\\nEquality of Opportunity Comparison:\")\n",
        "    print(f\"  Man TPR: {tpr_results['man']:.2f} | Woman TPR: {tpr_results['woman']:.2f}\")\n",
        "    print(f\"  Difference in TPR: {diff_tpr:.2f}\")\n",
        "else:\n",
        "    print(\"Unable to compute TPR for one or both groups.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_R-nC_RNxJR",
        "outputId": "5549c4d1-64e5-4ff8-d98d-2d395aeacee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPR (Equality of Opportunity) for man: 0.98\n",
            "TPR (Equality of Opportunity) for woman: 0.99\n",
            "\n",
            "Equality of Opportunity Comparison:\n",
            "  Man TPR: 0.98 | Woman TPR: 0.99\n",
            "  Difference in TPR: 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "\n",
        "# Assuming y_test and clf_gender (our trained classifier) are available.\n",
        "# Get predicted probabilities for the test set.\n",
        "probs = clf.predict_proba(X_test)  # shape: (n_samples, 2)\n",
        "\n",
        "# For demonstration, we compute the distribution of the predicted probability for class 1 (\"woman\")\n",
        "# for samples whose true labels belong to group 0 (\"man\") and group 1 (\"woman\").\n",
        "\n",
        "group0_probs = probs[y_test == 0, 1]  # Predicted probability of class 1 for true \"man\"\n",
        "group1_probs = probs[y_test == 1, 1]  # Predicted probability of class 1 for true \"woman\"\n",
        "\n",
        "# Create histograms (discrete distributions) for each group.\n",
        "# Here we use 10 bins between 0 and 1.\n",
        "bins = np.linspace(0, 1, 11)\n",
        "hist0, _ = np.histogram(group0_probs, bins=bins, density=True)\n",
        "hist1, _ = np.histogram(group1_probs, bins=bins, density=True)\n",
        "\n",
        "# Normalize the histograms so that they sum to 1.\n",
        "hist0 = hist0 / np.sum(hist0)\n",
        "hist1 = hist1 / np.sum(hist1)\n",
        "\n",
        "# Compute the KL-Divergence from group0's distribution to group1's distribution.\n",
        "kl_divergence = entropy(hist0, hist1)  # KL(P||Q)\n",
        "print(\"KL Divergence (man [group 0] vs woman [group 1]):\", kl_divergence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOYqJFdtSaSU",
        "outputId": "3a8d6860-4192-471c-cbc5-757e6836be3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KL Divergence (man [group 0] vs woman [group 1]): inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming y_test and y_pred are available as numpy arrays.\n",
        "# Define the mapping for readability.\n",
        "gender_map = {0: \"man\", 1: \"woman\"}\n",
        "\n",
        "def compute_ppv(y_true, y_pred, group_label):\n",
        "    # True Positives: correct predictions for the group.\n",
        "    tp = np.sum((y_true == group_label) & (y_pred == group_label))\n",
        "    # False Positives: samples from other groups predicted as this group.\n",
        "    fp = np.sum((y_true != group_label) & (y_pred == group_label))\n",
        "\n",
        "    ppv = tp / (tp + fp) if (tp + fp) != 0 else None\n",
        "    return ppv\n",
        "\n",
        "# Compute PPV for each group.\n",
        "ppv_results = {}\n",
        "for group in [0, 1]:\n",
        "    ppv_results[gender_map[group]] = compute_ppv(y_test, y_pred, group)\n",
        "\n",
        "# Display the PPV for each group.\n",
        "for gender, ppv in ppv_results.items():\n",
        "    if ppv is not None:\n",
        "        print(f\"PPV for {gender}: {ppv:.2f}\")\n",
        "    else:\n",
        "        print(f\"PPV for {gender}: Not computable (no predicted positives)\")\n",
        "\n",
        "# Compare the PPV differences between groups.\n",
        "if ppv_results[\"man\"] is not None and ppv_results[\"woman\"] is not None:\n",
        "    diff_ppv = abs(ppv_results[\"man\"] - ppv_results[\"woman\"])\n",
        "    print(\"\\nPredictive Parity Comparison:\")\n",
        "    print(f\"  Man PPV: {ppv_results['man']:.2f} | Woman PPV: {ppv_results['woman']:.2f}\")\n",
        "    print(f\"  Difference in PPV: {diff_ppv:.2f}\")\n",
        "else:\n",
        "    print(\"Unable to compute PPV for one or both groups.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPsDUs54TAIN",
        "outputId": "10f7e607-08ed-4f1d-9433-668fe91ef320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPV for man: 0.99\n",
            "PPV for woman: 0.98\n",
            "\n",
            "Predictive Parity Comparison:\n",
            "  Man PPV: 0.99 | Woman PPV: 0.98\n",
            "  Difference in PPV: 0.01\n"
          ]
        }
      ]
    }
  ]
}